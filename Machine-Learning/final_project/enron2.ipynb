{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata = pd.DataFrame.from_dict(data_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata = pdata.replace('NaN', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [print(x) for x in pdata['email_address']]\n",
    "# pdata['test'] = pdata['email_address'] == np.nan\n",
    "temp = []\n",
    "for el in pdata['email_address'].values:\n",
    "    if type(el) == float:\n",
    "        temp.append(False)\n",
    "    else:\n",
    "        temp.append(True)\n",
    "temp\n",
    "pdata['has_email_data'] = temp\n",
    "pdata['total_navalue_count'] = pdata.isnull().sum(axis=1)\n",
    "pdata['sal_navalue_count'] = pdata[['salary', 'deferral_payments', 'long_term_incentive', 'total_payments', 'bonus', 'expenses', 'loan_advances', 'other', 'director_fees', 'deferred_income']].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>has_email_data</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>35</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "has_email_data  False  True \n",
       "poi                         \n",
       "False              35     93\n",
       "True                0     18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count NA by column\n",
    "# pdata.isnull().sum()\n",
    "# count NA by row\n",
    "# pdata.isnull().sum(axis=1)\n",
    "# subset only email fields\n",
    "# pdata[['to_messages', 'shared_receipt_with_poi', 'from_messages', 'from_this_person_to_poi', 'from_poi_to_this_person']]\n",
    "# subset only rows with email data and examine ratio of pois in that group\n",
    "# email_only = pdata.dropna(subset=['to_messages'])\n",
    "# without = email_only['poi'].value_counts()\n",
    "# print('without Nan email data ratio: ', without[1]/float(without[0]))\n",
    "# print(email_only.shape)\n",
    "# wit = pdata['poi'].value_counts()\n",
    "# print('wit email Nan data ratio: ', wit[1]/float(wit[0]))\n",
    "# print(pdata.shape)\n",
    "pd.crosstab(pdata['poi'], pdata['has_email_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata['navalue_count'] = pdata.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # # Clean email only data\n",
    "# email_only = email_only.drop('email_address', 1)\n",
    "# email_only = email_only.replace(np.nan, 0, regex=True)\n",
    "# email_only = email_only[email_only.index != 'TOTAL']\n",
    "# Clean pdata\n",
    "# pdata = pdata.drop(['to_messages', 'shared_receipt_with_poi', 'from_messages', 'from_this_person_to_poi', 'from_poi_to_this_person', 'email_address'], 1)\n",
    "# pdata = pdata.replace(np.nan, 0, regex=True)\n",
    "# pdata = pdata[pdata.index != 'TOTAL']\n",
    "pdata = pdata.drop('email_address', 1)\n",
    "pdata = pdata.replace(np.nan, 0, regex=True)\n",
    "pdata = pdata[pdata.index != 'TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata['short_gain'] = pdata['exercised_stock_options'] - pdata['long_term_incentive']\n",
    "# gr = pdata.groupby(['poi'])\n",
    "# gr['short_gain'].median()\n",
    "# gr['exercised_stock_options'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'FREVERT MARK A', 'LAY KENNETH L',\n",
    "# outies = ['FREVERT MARK A', 'LAY KENNETH L', 'SKILLING JEFFREY K']\n",
    "# pdata = pdata.drop(outies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALLEN PHILLIP K                   True\n",
       "BADUM JAMES P                     True\n",
       "BANNANTINE JAMES M                True\n",
       "BAXTER JOHN C                     True\n",
       "BAY FRANKLIN R                    True\n",
       "BAZELIDES PHILIP J                True\n",
       "BECK SALLY W                      True\n",
       "BELDEN TIMOTHY N                  True\n",
       "BELFER ROBERT                    False\n",
       "BERBERIAN DAVID                   True\n",
       "BERGSIEKER RICHARD P              True\n",
       "BHATNAGAR SANJAY                 False\n",
       "BIBI PHILIPPE A                   True\n",
       "BLACHMAN JEREMY M                 True\n",
       "BLAKE JR. NORMAN P                True\n",
       "BOWEN JR RAYMOND M                True\n",
       "BROWN MICHAEL                     True\n",
       "BUCHANAN HAROLD G                 True\n",
       "BUTTS ROBERT H                    True\n",
       "BUY RICHARD B                     True\n",
       "CALGER CHRISTOPHER F              True\n",
       "CARTER REBECCA C                  True\n",
       "CAUSEY RICHARD A                  True\n",
       "CHAN RONNIE                       True\n",
       "CHRISTODOULOU DIOMEDES            True\n",
       "CLINE KENNETH W                   True\n",
       "COLWELL WESLEY                    True\n",
       "CORDES WILLIAM R                  True\n",
       "COX DAVID                         True\n",
       "CUMBERLAND MICHAEL S              True\n",
       "                                 ...  \n",
       "SCRIMSHAW MATTHEW                 True\n",
       "SHANKMAN JEFFREY A                True\n",
       "SHAPIRO RICHARD S                 True\n",
       "SHARP VICTORIA T                  True\n",
       "SHELBY REX                        True\n",
       "SHERRICK JEFFREY B                True\n",
       "SHERRIFF JOHN R                   True\n",
       "SKILLING JEFFREY K                True\n",
       "STABLER FRANK                     True\n",
       "SULLIVAN-SHAKLOVITZ COLLEEN       True\n",
       "SUNDE MARTIN                      True\n",
       "TAYLOR MITCHELL S                 True\n",
       "THE TRAVEL AGENCY IN THE PARK     True\n",
       "THORN TERENCE H                   True\n",
       "TILNEY ELIZABETH A                True\n",
       "UMANOFF ADAM S                    True\n",
       "URQUHART JOHN A                   True\n",
       "WAKEHAM JOHN                      True\n",
       "WALLS JR ROBERT H                 True\n",
       "WALTERS GARETH W                  True\n",
       "WASAFF GEORGE                     True\n",
       "WESTFAHL RICHARD K                True\n",
       "WHALEY DAVID A                    True\n",
       "WHALLEY LAWRENCE G                True\n",
       "WHITE JR THOMAS E                 True\n",
       "WINOKUR JR. HERBERT S             True\n",
       "WODRASKA JOHN                     True\n",
       "WROBEL BRUCE                      True\n",
       "YEAGER F SCOTT                    True\n",
       "YEAP SOON                         True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach 1\n",
    "# Use only rows that contain email data\n",
    "temp = pdata['salary'] + pdata['bonus'] + pdata['long_term_incentive'] + \\\n",
    "    pdata['deferred_income'] + pdata['deferral_payments'] + pdata['loan_advances'] + \\\n",
    "    pdata['other'] + pdata['expenses'] + pdata['director_fees']\n",
    "temp == pdata['total_payments']\n",
    "# BELFER ROBERT and BHATNAGAR SANJAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata = pdata[pdata.index != 'LAY KENNETH L']\n",
    "pdata = pdata[pdata.index != 'BELFER ROBERT']\n",
    "pdata = pdata[pdata.index != 'BHATNAGAR SANJAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pdata['exercised_stock_options'] + pdata['restricted_stock'] + pdata['restricted_stock_deferred']\n",
    "len(pdata) -(temp == pdata['total_stock_value']).sum()\n",
    "# excellent. indicates no mismatch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata['sal_ratio'] = (pdata['bonus'] + pdata['long_term_incentive'] + pdata['expenses']) / pdata['total_payments']\n",
    "pdata['stock_ratio'] = pdata['restricted_stock'] / pdata['total_stock_value']\n",
    "pdata['em_ratio'] = (pdata['shared_receipt_with_poi'] + pdata['from_this_person_to_poi'] + pdata['from_poi_to_this_person'] ) / (pdata['to_messages'] + pdata['from_messages'])\n",
    "pdata['total_total'] = pdata['total_payments'] + pdata['total_stock_value']\n",
    "pdata['from_ratio'] = pdata['from_this_person_to_poi'] / pdata['from_messages']\n",
    "pdata['sent_ratio'] = (pdata['from_poi_to_this_person'] + pdata['shared_receipt_with_poi']) / pdata['to_messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pdata = pdata.drop('total_payments', 1)\n",
    "# pdata = pdata.drop('total_stock_value', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# edata = email_only.T.to_dict()\n",
    "pdata = pdata.replace(np.nan, 0, regex=True)\n",
    "pdata = pdata.replace(np.inf, 0, regex=True)\n",
    "pdata = pdata.replace(-np.inf, 0, regex=True)\n",
    "pdict = pdata.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\n",
    "       'exercised_stock_options', 'bonus', 'restricted_stock',\n",
    "       'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value',\n",
    "       'expenses', 'from_messages', 'other', 'from_this_person_to_poi',\n",
    "       'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person', 'from_ratio', 'sent_ratio',\n",
    "       'sal_ratio', 'stock_ratio', 'em_ratio', 'has_email_data', 'total_navalue_count','sal_navalue_count', 'total_total', 'short_gain']\n",
    "print(len(features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = pdict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary\n",
      "total_payments\n",
      "exercised_stock_options\n",
      "bonus\n",
      "deferred_income\n",
      "from_ratio\n",
      "sent_ratio\n",
      "sal_ratio\n",
      "em_ratio\n",
      "total_navalue_count\n",
      "sal_navalue_count\n",
      "total_total\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "x_new = SelectKBest(k=12)\n",
    "x_new.fit_transform(features_train, labels_train)\n",
    "#model = SVC(kernel='linear', C=6).fit(features_train, labels_train)\n",
    "#print(model)\n",
    "for i in range(len(x_new.get_support())):\n",
    "    if x_new.get_support()[i]:\n",
    "        print(features_list[i+1])\n",
    "# features_list[x_new.get_support()]\n",
    "#accuracy_score(labels_test, model.predict(features_test))\n",
    "# print(x_new.scores_)\n",
    "# # tups = {}\n",
    "# # for i in range(27):\n",
    "# #     tups[features_list[i+1]] = x_new.scores_[i]\n",
    "# # for w in sorted(tups, key=tups.get, reverse=True):\n",
    "# #   print w, tups[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 1, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(0, 0.90697674418604646, 0.5, 0.25)\n",
      "bonus\n",
      "{'k': 2, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(1, 0.90697674418604646, 0.5, 0.25)\n",
      "salary\n",
      "bonus\n",
      "{'k': 3, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(2, 0.88372093023255816, 0.33333333333333331, 0.25)\n",
      "salary\n",
      "bonus\n",
      "total_stock_value\n",
      "{'k': 4, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(3, 0.88372093023255816, 0.33333333333333331, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "{'k': 5, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(4, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "from_ratio\n",
      "{'k': 6, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(5, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "from_ratio\n",
      "short_gain\n",
      "{'k': 7, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(6, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "deferred_income\n",
      "from_ratio\n",
      "short_gain\n",
      "{'k': 8, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(7, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "deferred_income\n",
      "from_ratio\n",
      "total_total\n",
      "short_gain\n",
      "{'k': 9, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(8, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "deferred_income\n",
      "from_ratio\n",
      "sal_ratio\n",
      "total_total\n",
      "short_gain\n",
      "{'k': 10, 'score_func': <function f_classif at 0x1086cab18>}\n",
      "(9, 0.86046511627906974, 0.25, 0.25)\n",
      "salary\n",
      "total_payments\n",
      "exercised_stock_options\n",
      "bonus\n",
      "total_stock_value\n",
      "deferred_income\n",
      "from_ratio\n",
      "sal_ratio\n",
      "total_total\n",
      "short_gain\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "for i in range(10):\n",
    "    x_new = SelectKBest(k=i+1)\n",
    "    x_new.fit_transform(features_train, labels_train)\n",
    "    print(x_new.get_params())\n",
    "    model = SVC(kernel='linear', C=i+1).fit(features_train, labels_train)\n",
    "    pred = model.predict(features_test)\n",
    "    print(i, accuracy_score(labels_test, pred), precision_score(labels_test, pred), recall_score(labels_test, pred))\n",
    "    for i in range(len(x_new.get_support())):\n",
    "        if x_new.get_support()[i]:\n",
    "            print(features_list[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90697674418604646"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "selection = SelectKBest(k=10)\n",
    "# combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "# X_features = combined_features.fit(features_train, labels_train).transform(features_train)\n",
    "svm = SVC(kernel=\"linear\")\n",
    "pipeline = Pipeline([('univ_select', selection), (\"svm\", svm)])\n",
    "# param_grid = dict(features__pca__n_components=[1, 2, 3],\n",
    "#                   features__univ_select__k=[1, 2, 3],\n",
    "#                   svm__C=[0.1, 1, 5, 10])\n",
    "# grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)\n",
    "# grid_search.fit(features_train, labels_train)\n",
    "model = pipeline.fit(features_train, labels_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# pred = grid_search.best_estimator_.predict(features_test)\n",
    "pred = model.predict(features_test)\n",
    "print(pred)\n",
    "accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "features_list = ['poi', 'total_total', 'from_ratio']\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)    \n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "model = SVC(kernel='linear', C=5).fit(features_train, labels_train)\n",
    "\n",
    "print('this is the model:')\n",
    "print(model)\n",
    "\n",
    "scores = cross_validation.cross_val_score(model, features, labels, cv=10)\n",
    "\n",
    "print('these are the xval scores:')\n",
    "print(scores)\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(model, features, labels, cv=10)\n",
    "\n",
    "print('accuracy:', accuracy_score(labels, predicted))\n",
    "print('recall: ', recall_score(labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features_list = ['poi', 'bonus', 'salary', 'total_stock_value', 'deferred_income',\n",
    "#                  'short_gain', 'total_total', 'sal_ratio',\n",
    "#                  'shared_receipt_with_poi', 'restricted_stock', 'em_ratio', 'other']\n",
    "\n",
    "# features_list = ['poi', 'salary', 'bonus', 'total_stock_value', 'exercised_stock_options',\n",
    "#                  'from_ratio', 'short_gain', 'deferred_income', 'total_total', 'sal_ratio',\n",
    "#                  'total_payments']\n",
    "\n",
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\n",
    "       'exercised_stock_options', 'bonus', 'restricted_stock',\n",
    "       'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value',\n",
    "       'expenses', 'from_messages', 'other', 'from_this_person_to_poi',\n",
    "       'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person', 'from_ratio', 'sent_ratio',\n",
    "       'sal_ratio', 'stock_ratio', 'em_ratio', 'has_email_data', 'navalue_count', 'total_total', 'short_gain']\n",
    "\n",
    "#                  'exercised_stock_options', 'bonus', 'total_stock_value', \n",
    "#                  'expenses', 'other', 'shared_receipt_with_poi', 'salary']\n",
    "#                  'navalue_count', 'shared_receipt_with_poi', 'stock_ratio', 'deferred_income', 'salary',\n",
    "#                  'from_poi_to_this_person', 'from_this_person_to_poi', 'sal_ratio', 'long_term_incentive',\n",
    "#'sal_ratio', 'em_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.]\n",
      "0.906976744186\n",
      "0.5\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)    \n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_split=10)\n",
    "rfc.fit(features_train, labels_train)\n",
    "\n",
    "pred = rfc.predict(features_test)\n",
    "print(pred)\n",
    "\n",
    "print(accuracy_score(labels_test, pred))\n",
    "print(precision_score(labels_test, pred))\n",
    "print(recall_score(labels_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('salary', ': ', 0.029018184001189877)\n",
      "('to_messages', ': ', 0.023409306048003287)\n",
      "('deferral_payments', ': ', 0.0049931521507208965)\n",
      "('total_payments', ': ', 0.034898477060406614)\n",
      "('exercised_stock_options', ': ', 0.071402652691724036)\n",
      "('bonus', ': ', 0.074083535054793537)\n",
      "('restricted_stock', ': ', 0.049646367292265514)\n",
      "('shared_receipt_with_poi', ': ', 0.035370213416170415)\n",
      "('restricted_stock_deferred', ': ', 0.0)\n",
      "('total_stock_value', ': ', 0.042895905516350939)\n",
      "('expenses', ': ', 0.046640237897074756)\n",
      "('from_messages', ': ', 0.005435517893799903)\n",
      "('other', ': ', 0.10019571125026454)\n",
      "('from_this_person_to_poi', ': ', 0.023254399128601388)\n",
      "('director_fees', ': ', 0.0)\n",
      "('deferred_income', ': ', 0.032036870067940731)\n",
      "('long_term_incentive', ': ', 0.050550767791367822)\n",
      "('from_poi_to_this_person', ': ', 0.014440498836177207)\n",
      "('from_ratio', ': ', 0.0789018050661702)\n",
      "('sent_ratio', ': ', 0.0309714436957562)\n",
      "('sal_ratio', ': ', 0.027447181626463191)\n",
      "('stock_ratio', ': ', 0.023556868550838536)\n",
      "('em_ratio', ': ', 0.018288440488416075)\n",
      "('has_email_data', ': ', 0.0)\n",
      "('navalue_count', ': ', 0.012929485823497802)\n",
      "('total_total', ': ', 0.084310079319676698)\n",
      "('short_gain', ': ', 0.085322899332329741)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rfc.feature_importances_)):\n",
    "    print(features_list[i+1], \": \", rfc.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.90697674418604646)\n",
      "('Precision: ', 0.5)\n",
      "('Recall: ', 0.25)\n",
      "('F1: ', 0.33333333333333331)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(features)    \n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "        \n",
    "    pca = RandomizedPCA(n_components=1,whiten=True)#.fit(features_train)\n",
    "    rfc = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_split=10)\n",
    "    pipe = Pipeline(steps=[('pca', pca), ('rfc', rfc)])\n",
    "    pipe.fit(features_train, labels_train)\n",
    "    pred = pipe.predict(features_test)    \n",
    "\n",
    "#     rfc = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_split=10)\n",
    "#     rfc.fit(features_train, labels_train)\n",
    "#     pred = rfc.predict(features_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    f1.append(f1_score(labels_test, pred))\n",
    "    \n",
    "print('Accuracy: ', np.mean(accuracy))\n",
    "print('Precision: ', np.mean(precision))\n",
    "print('Recall: ', np.mean(recall))\n",
    "print('F1: ', np.mean(f1))\n",
    "\n",
    "\n",
    "# ('Accuracy: ', 0.90697674418604646)\n",
    "# ('Precision: ', 0.5)\n",
    "# ('Recall: ', 0.25)\n",
    "# ('F1: ', 0.33333333333333331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person', 'from_ratio', 'sent_ratio', 'sal_ratio', 'stock_ratio', 'em_ratio', 'has_email_data', 'navalue_count', 'total_total', 'short_gain']\n",
      "('Accuracy: ', 0.90697674418604657)\n",
      "('Precision: ', 0.5)\n",
      "('Recall: ', 0.5)\n",
      "('F1: ', 0.5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "print(features_list)\n",
    "\n",
    "for i in range(500):\n",
    "    \n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    \n",
    "#     scaler = MinMaxScaler()\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)    \n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "#     pca = RandomizedPCA(n_components=2,whiten=True)#.fit(features_train)\n",
    "    \n",
    "#     features_train_pca = pca.transform(features_train)\n",
    "#     features_test_pca = pca.transform(features_test)\n",
    "#     pca_score = pca.explained_variance_ratio_\n",
    "#     print pca_score\n",
    "    \n",
    "    svm = SVC(kernel='linear', C=5.0)\n",
    "    svm.fit(features_train, labels_train)\n",
    "\n",
    "#     pipe = Pipeline(steps=[('pca', pca), ('svm', svm)])\n",
    "\n",
    "#     pipe.fit(features_train, labels_train)\n",
    "\n",
    "#     pred = pipe.predict(features_test)\n",
    "\n",
    "    pred = svm.predict(features_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    f1.append(f1_score(labels_test, pred))\n",
    "    \n",
    "print('Accuracy: ', np.mean(accuracy))\n",
    "print('Precision: ', np.mean(precision))\n",
    "print('Recall: ', np.mean(recall))\n",
    "print('F1: ', np.mean(f1))\n",
    "\n",
    "# ('Accuracy: ', 0.90697674418604679)\n",
    "# ('Precision: ', 0.66666666666666685)\n",
    "# ('Recall: ', 0.39999999999999991)\n",
    "# ('F1: ', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.79069767441860461)\n",
      "('Precision: ', 0.25)\n",
      "('Recall: ', 0.39999999999999991)\n",
      "('F1: ', 0.3076923076923076)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(features)    \n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    pca = RandomizedPCA(n_components=2,whiten=True).fit(features_train)\n",
    "    \n",
    "    features_train_pca = pca.transform(features_train)\n",
    "    features_test_pca = pca.transform(features_test)\n",
    "#     pca_score = pca.explained_variance_ratio_\n",
    "#     print pca_score\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=2, p=1, weights='distance')\n",
    "    neigh.fit(features_train_pca, labels_train)\n",
    "\n",
    "#     pipe = Pipeline(steps=[('pca', pca), ('svm', svm)])\n",
    "\n",
    "#     pipe.fit(features_train, labels_train)\n",
    "\n",
    "#     pred = pipe.predict(features_test)\n",
    "\n",
    "    #print(neigh)\n",
    "\n",
    "    pred = neigh.predict(features_test_pca)\n",
    "    \n",
    "    #print(neigh)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    f1.append(f1_score(labels_test, pred))\n",
    "    \n",
    "print('Accuracy: ', np.mean(accuracy))\n",
    "print('Precision: ', np.mean(precision))\n",
    "print('Recall: ', np.mean(recall))\n",
    "print('F1: ', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
